{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved CNN for FT of MNIST data. Also padded size.\n",
    "\n",
    "### v3 introduces 2 channels of intensity and phase to see if accuracy improves\n",
    "\n",
    "### v4 introduces hyperas to do hyper-param optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "apJbCsBHl-2A"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Choose GPUs and CPUs\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#If want to choose GPU to use\n",
    "#This will make it so that only the 0th GPU is visible to TensorFlow.\n",
    "#In your case, you can choose any in the range [0, 3].\n",
    "#If you wanted, for example, the 0th and 2nd GPUs to both be visible, replace \"0\" with \"0,2\"\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "GPU=True\n",
    "CPU=False\n",
    "num_cores = 8\n",
    "\n",
    "if GPU:\n",
    "    num_GPU = 2\n",
    "    num_CPU = 2\n",
    "if CPU:\n",
    "    num_CPU = num_cores\n",
    "    num_GPU = 0\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : num_CPU, 'GPU' : num_GPU},\\\n",
    "#        gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.5))\n",
    "                       )\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical, multi_gpu_model\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.fftpack import fftn,fftshift\n",
    "\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice,uniform\n",
    "\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST data from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 28, 28\n",
    "    num_classes=10\n",
    "\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    train_dataset = x_train.astype('float32')\n",
    "    test_dataset = x_test.astype('float32')\n",
    "    train_dataset /= 255\n",
    "    test_dataset /= 255\n",
    "    print('train_dataset shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    train_labels = keras.utils.to_categorical(y_train, num_classes)\n",
    "    test_labels = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "    # Pad numpy array\n",
    "    # Want 36x36 which is how big the multiMNIST will be\n",
    "    train_dataset=np.pad(train_dataset, ((0,0),(4,4),(4,4),(0,0)), 'constant', constant_values=(0,0))\n",
    "    print (train_dataset.shape)\n",
    "\n",
    "    test_dataset=np.pad(test_dataset, ((0,0),(4,4),(4,4),(0,0)), 'constant', constant_values=(0,0))\n",
    "    print (test_dataset.shape)\n",
    "\n",
    "    # Take FT\n",
    "    dims=train_dataset.shape\n",
    "    ft_train=np.zeros((dims[0], 36, 36, 2), float)\n",
    "    for i in range(dims[0]):\n",
    "        ft_train[i,:,:,0]=np.abs(fftshift(fftn(train_dataset[i,:,:]))).squeeze()\n",
    "        ft_train[i,:,:,1]=np.angle(fftshift(fftn(train_dataset[i,:,:]))).squeeze()\n",
    "    #    ft_train[i,:,:,1]=unwrap_phase(ft_train[i,:,:,1])\n",
    "\n",
    "    dims=test_dataset.shape\n",
    "    ft_test=np.zeros((dims[0], 36, 36, 2), float)\n",
    "    for i in tqdm_notebook(range(dims[0])):\n",
    "        ft_test[i,:,:,0]=np.abs(fftshift(fftn(test_dataset[i,:,:]))).squeeze()\n",
    "        ft_test[i,:,:,1]=np.angle(fftshift(fftn(test_dataset[i,:,:]))).squeeze()\n",
    "    #    ft_test[i,:,:,1]=unwrap_phase(ft_test[i,:,:,1])\n",
    "\n",
    "\n",
    "    dims=ft_train.shape\n",
    "    print (dims)\n",
    "    trainee=ft_train.reshape(dims[0],dims[1],dims[2],2)\n",
    "    dims=test_dataset.shape\n",
    "    testee=ft_test.reshape(dims[0],dims[1],dims[2],2)\n",
    "    print (trainee.shape)\n",
    "    return trainee, train_labels, testee, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O.K now try CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass ModelMGPU(Model):\\n    def __init__(self, ser_model, gpus):\\n        pmodel = multi_gpu_model(ser_model, gpus)\\n        self.__dict__.update(pmodel.__dict__)\\n        self._smodel = ser_model\\n\\n    def __getattribute__(self, attrname):\\n        '''Override load and save methods to be used from the serial-model. The\\n        serial-model holds references to the weights in the multi-gpu model.\\n        '''\\n        # return Model.__getattribute__(self, attrname)\\n        if 'load' in attrname or 'save' in attrname:\\n            return getattr(self._smodel, attrname)\\n\\n        return super(ModelMGPU, self).__getattribute__(attrname)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class ModelMGPU(Model):\n",
    "    def __init__(self, ser_model, gpus):\n",
    "        pmodel = multi_gpu_model(ser_model, gpus)\n",
    "        self.__dict__.update(pmodel.__dict__)\n",
    "        self._smodel = ser_model\n",
    "\n",
    "    def __getattribute__(self, attrname):\n",
    "        '''Override load and save methods to be used from the serial-model. The\n",
    "        serial-model holds references to the weights in the multi-gpu model.\n",
    "        '''\n",
    "        # return Model.__getattribute__(self, attrname)\n",
    "        if 'load' in attrname or 'save' in attrname:\n",
    "            return getattr(self._smodel, attrname)\n",
    "\n",
    "        return super(ModelMGPU, self).__getattribute__(attrname)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Conv2D, MaxPool2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential, Model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Dropout, Activation, Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import to_categorical, multi_gpu_model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tqdm import tqdm_notebook\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from scipy.fftpack import fftn, fftshift\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0.1, 0.9),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0.1, 0.9),\n",
      "        'Dropout_2': hp.choice('Dropout_2', [0,1]),\n",
      "        'Dropout_3': hp.uniform('Dropout_3', 0.1, 0.9),\n",
      "        'Dropout_4': hp.uniform('Dropout_4', 0.1, 0.9),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: # input image dimensions\n",
      "   3: img_rows, img_cols = 28, 28\n",
      "   4: num_classes=10\n",
      "   5: \n",
      "   6: # the data, split between train and test sets\n",
      "   7: (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
      "   8: \n",
      "   9: if K.image_data_format() == 'channels_first':\n",
      "  10:     x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
      "  11:     x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
      "  12:     input_shape = (1, img_rows, img_cols)\n",
      "  13: else:\n",
      "  14:     x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
      "  15:     x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
      "  16:     input_shape = (img_rows, img_cols, 1)\n",
      "  17: \n",
      "  18: train_dataset = x_train.astype('float32')\n",
      "  19: test_dataset = x_test.astype('float32')\n",
      "  20: train_dataset /= 255\n",
      "  21: test_dataset /= 255\n",
      "  22: print('train_dataset shape:', x_train.shape)\n",
      "  23: print(x_train.shape[0], 'train samples')\n",
      "  24: print(x_test.shape[0], 'test samples')\n",
      "  25: \n",
      "  26: # convert class vectors to binary class matrices\n",
      "  27: train_labels = keras.utils.to_categorical(y_train, num_classes)\n",
      "  28: test_labels = keras.utils.to_categorical(y_test, num_classes)\n",
      "  29: \n",
      "  30: \n",
      "  31: # Pad numpy array\n",
      "  32: # Want 36x36 which is how big the multiMNIST will be\n",
      "  33: train_dataset=np.pad(train_dataset, ((0,0),(4,4),(4,4),(0,0)), 'constant', constant_values=(0,0))\n",
      "  34: print (train_dataset.shape)\n",
      "  35: \n",
      "  36: test_dataset=np.pad(test_dataset, ((0,0),(4,4),(4,4),(0,0)), 'constant', constant_values=(0,0))\n",
      "  37: print (test_dataset.shape)\n",
      "  38: \n",
      "  39: # Take FT\n",
      "  40: dims=train_dataset.shape\n",
      "  41: ft_train=np.zeros((dims[0], 36, 36, 2), float)\n",
      "  42: for i in range(dims[0]):\n",
      "  43:     ft_train[i,:,:,0]=np.abs(fftshift(fftn(train_dataset[i,:,:]))).squeeze()\n",
      "  44:     ft_train[i,:,:,1]=np.angle(fftshift(fftn(train_dataset[i,:,:]))).squeeze()\n",
      "  45: #    ft_train[i,:,:,1]=unwrap_phase(ft_train[i,:,:,1])\n",
      "  46: \n",
      "  47: dims=test_dataset.shape\n",
      "  48: ft_test=np.zeros((dims[0], 36, 36, 2), float)\n",
      "  49: for i in tqdm_notebook(range(dims[0])):\n",
      "  50:     ft_test[i,:,:,0]=np.abs(fftshift(fftn(test_dataset[i,:,:]))).squeeze()\n",
      "  51:     ft_test[i,:,:,1]=np.angle(fftshift(fftn(test_dataset[i,:,:]))).squeeze()\n",
      "  52: #    ft_test[i,:,:,1]=unwrap_phase(ft_test[i,:,:,1])\n",
      "  53: \n",
      "  54: \n",
      "  55: dims=ft_train.shape\n",
      "  56: print (dims)\n",
      "  57: trainee=ft_train.reshape(dims[0],dims[1],dims[2],2)\n",
      "  58: dims=test_dataset.shape\n",
      "  59: testee=ft_test.reshape(dims[0],dims[1],dims[2],2)\n",
      "  60: print (trainee.shape)\n",
      "  61: \n",
      "  62: \n",
      "  63: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3: \n",
      "   4: \n",
      "   5:     w_size = 3 #w_size= 3 is always recommended\n",
      "   6:     model=Sequential()\n",
      "   7: \n",
      "   8:     model.add(Conv2D(32,(w_size,w_size), activation='relu', input_shape=(36,36,2),\n",
      "   9:                      data_format='channels_last', padding='same'))\n",
      "  10:     model.add(Conv2D(32,(w_size,w_size), activation='relu', padding='same'))\n",
      "  11:     model.add(MaxPool2D(pool_size=(2,2)))\n",
      "  12:     model.add(Conv2D(64,(w_size,w_size), activation='relu', padding='same'))\n",
      "  13:     model.add(Conv2D(64,(w_size,w_size), activation='relu', padding='same'))\n",
      "  14:     model.add(Dropout(space['Dropout']))\n",
      "  15:     model.add(MaxPool2D(pool_size=(2,2)))\n",
      "  16:     model.add(Conv2D(128,(w_size,w_size), activation='relu', padding='same'))\n",
      "  17:     model.add(Conv2D(128,(w_size,w_size), activation='relu', padding='same'))\n",
      "  18:     model.add(Dropout(space['Dropout_1']))\n",
      "  19:     model.add(MaxPool2D(pool_size=(2,2)))\n",
      "  20:     \n",
      "  21:     if space['Dropout_2']: #Do we need to go deeper?\n",
      "  22:         model.add(Conv2D(256,(w_size,w_size), activation='relu', padding='same'))\n",
      "  23:         model.add(Conv2D(256,(w_size,w_size), activation='relu', padding='same'))\n",
      "  24:         model.add(Dropout(space['Dropout_3']))\n",
      "  25:         model.add(MaxPool2D(pool_size=(2,2)))\n",
      "  26:         \n",
      "  27:     model.add(Flatten())\n",
      "  28:     model.add(Dense(600, activation='relu'))\n",
      "  29:     model.add(Dropout(space['Dropout_4']))\n",
      "  30:     model.add(Dense(10, activation='sigmoid')) \n",
      "  31: \n",
      "  32:     #parallel_model = ModelMGPU(model, gpus=num_GPU)\n",
      "  33:     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
      "  34:     \n",
      "  35:     history=model.fit(trainee, train_labels, batch_size=256, verbose=0, epochs=10, \n",
      "  36:                   validation_split = 0.1)#, callbacks=[checkpoints])\n",
      "  37:     \n",
      "  38:     score=model.evaluate(testee, test_labels)\n",
      "  39:     \n",
      "  40:     #get the highest validation accuracy of the training epochs\n",
      "  41:     validation_acc = np.amax(history.history['val_acc'])\n",
      "  42:     print(validation_acc)\n",
      "  43:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
      "  44: \n",
      "train_dataset shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "(60000, 36, 36, 1)\n",
      "(10000, 36, 36, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcherukara/miniconda3/envs/gpu/lib/python3.6/site-packages/scipy/fftpack/basic.py:160: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  z[index] = x\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca527829abc48d68d10d8bab6152268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(60000, 36, 36, 2)\n",
      "(60000, 36, 36, 2)\n",
      "10000/10000 [==============================] - 1s 59us/step\n",
      "0.9813333328564962\n",
      "10000/10000 [==============================] - 1s 50us/step\n",
      "0.9828333328564962\n",
      "10000/10000 [==============================] - 1s 56us/step\n",
      "0.9796666661898296\n",
      "10000/10000 [==============================] - 1s 59us/step\n",
      "0.0978333332935969\n",
      "10000/10000 [==============================] - 1s 57us/step\n",
      "0.9831666661898295\n",
      "10000/10000 [==============================] - 1s 52us/step\n",
      "0.0978333332935969\n",
      "10000/10000 [==============================] - 1s 52us/step\n",
      "0.9838333328564962\n",
      "10000/10000 [==============================] - 1s 54us/step\n",
      "0.9819999995231629\n",
      "10000/10000 [==============================] - 1s 61us/step\n",
      "0.0978333332935969\n",
      "10000/10000 [==============================] - 1s 60us/step\n",
      "0.9784999995231628\n",
      "10000/10000 [==============================] - 1s 56us/step\n",
      "0.9856666661898295\n",
      "10000/10000 [==============================] - 1s 63us/step\n",
      "0.9829999995231629\n",
      "10000/10000 [==============================] - 1s 65us/step\n",
      "0.9779999995231629\n",
      "10000/10000 [==============================] - 1s 64us/step\n",
      "0.9786666661898296\n",
      "10000/10000 [==============================] - 1s 66us/step\n",
      "0.9793333328564962\n",
      "10000/10000 [==============================] - 1s 59us/step\n",
      "0.9834999995231628\n",
      "10000/10000 [==============================] - 1s 66us/step\n",
      "0.10500000003973643\n",
      "10000/10000 [==============================] - 1s 66us/step\n",
      "0.0978333332935969\n",
      "10000/10000 [==============================] - 1s 69us/step\n",
      "0.9831666661898295\n",
      "10000/10000 [==============================] - 1s 70us/step\n",
      "0.9761666661898295\n",
      "10000/10000 [==============================] - 1s 64us/step\n",
      "0.09949999996026357\n",
      "10000/10000 [==============================] - 1s 64us/step\n",
      "0.9844999995231628\n",
      "10000/10000 [==============================] - 1s 64us/step\n",
      "0.0978333332935969\n",
      "10000/10000 [==============================] - 1s 65us/step\n",
      "0.9841666661898295\n",
      "10000/10000 [==============================] - 1s 68us/step\n",
      "0.9806666661898296\n",
      "10000/10000 [==============================] - 1s 68us/step\n",
      "0.9841666661898295\n",
      "10000/10000 [==============================] - 1s 69us/step\n",
      "0.9829999995231629\n",
      "10000/10000 [==============================] - 1s 70us/step\n",
      "0.9838333328564962\n",
      "10000/10000 [==============================] - 1s 74us/step\n",
      "0.9836666661898296\n",
      "10000/10000 [==============================] - 1s 73us/step\n",
      "0.9826666661898296\n",
      "10000/10000 [==============================] - 1s 73us/step\n",
      "0.9839999995231629\n",
      "10000/10000 [==============================] - 1s 74us/step\n",
      "0.9824999995231628\n",
      "10000/10000 [==============================] - 1s 78us/step\n",
      "0.9821666661898295\n",
      "10000/10000 [==============================] - 1s 76us/step\n",
      "0.9849999995231629\n",
      "10000/10000 [==============================] - 1s 79us/step\n",
      "0.14516666666666667\n",
      "10000/10000 [==============================] - 1s 81us/step\n",
      "0.9849999995231629\n",
      "10000/10000 [==============================] - 1s 79us/step\n",
      "0.9839999995231629\n",
      "10000/10000 [==============================] - 1s 83us/step\n",
      "0.9853333328564962\n",
      "10000/10000 [==============================] - 1s 82us/step\n",
      "0.13500000003973642\n",
      "10000/10000 [==============================] - 1s 83us/step\n",
      "0.9836666661898296\n",
      "10000/10000 [==============================] - 1s 85us/step\n",
      "0.15566666670640308\n",
      "10000/10000 [==============================] - 1s 88us/step\n",
      "0.9841666661898295\n",
      "10000/10000 [==============================] - 1s 87us/step\n",
      "0.9829999995231629\n",
      "10000/10000 [==============================] - 1s 87us/step\n",
      "0.11649999988079071\n",
      "10000/10000 [==============================] - 1s 88us/step\n",
      "0.9841666661898295\n",
      "10000/10000 [==============================] - 1s 84us/step\n",
      "0.0978333332935969\n",
      "10000/10000 [==============================] - 1s 94us/step\n",
      "0.9813333328564962\n",
      "10000/10000 [==============================] - 1s 90us/step\n",
      "0.9828333328564962\n",
      "10000/10000 [==============================] - 1s 98us/step\n",
      "0.09150000003973643\n",
      "10000/10000 [==============================] - 1s 91us/step\n",
      "0.0978333332935969\n",
      "10000/10000 [==============================] - 1s 96us/step\n",
      "0.10583333337306976\n",
      "10000/10000 [==============================] - 1s 94us/step\n",
      "0.9836666661898296\n",
      "10000/10000 [==============================] - 1s 102us/step\n",
      "0.0978333332935969\n",
      "10000/10000 [==============================] - 1s 96us/step\n",
      "0.13133333337306977\n",
      "10000/10000 [==============================] - 1s 99us/step\n",
      "0.0978333332935969\n",
      "10000/10000 [==============================] - 1s 109us/step\n",
      "0.10816666678587596\n",
      "10000/10000 [==============================] - 1s 101us/step\n",
      "0.9829999995231629\n",
      "10000/10000 [==============================] - 1s 101us/step\n",
      "0.9818333334922791\n",
      "10000/10000 [==============================] - 1s 102us/step\n",
      "0.9838333328564962\n",
      "10000/10000 [==============================] - 1s 111us/step\n",
      "0.15200000003973643\n",
      "10000/10000 [==============================] - 1s 106us/step\n",
      "0.9861666661898295\n",
      "10000/10000 [==============================] - 1s 105us/step\n",
      "0.9833333328564962\n",
      "10000/10000 [==============================] - 1s 106us/step\n",
      "0.9853333328564962\n",
      "10000/10000 [==============================] - 1s 112us/step\n",
      "0.9806666661898296\n",
      "10000/10000 [==============================] - 1s 111us/step\n",
      "0.9819999995231629\n",
      "10000/10000 [==============================] - 1s 110us/step\n",
      "0.11433333335320155\n",
      "10000/10000 [==============================] - 1s 111us/step\n",
      "0.9823333328564962\n",
      "10000/10000 [==============================] - 1s 113us/step\n",
      "0.9831666661898295\n",
      "10000/10000 [==============================] - 1s 112us/step\n",
      "0.9809999995231629\n",
      "10000/10000 [==============================] - 1s 115us/step\n",
      "0.9826666661898296\n",
      "10000/10000 [==============================] - 1s 116us/step\n",
      "0.9813333328564962\n",
      "10000/10000 [==============================] - 1s 116us/step\n",
      "0.0978333332935969\n",
      "10000/10000 [==============================] - 1s 115us/step\n",
      "0.0978333332935969\n",
      "10000/10000 [==============================] - 1s 116us/step\n",
      "0.9831666661898295\n",
      "10000/10000 [==============================] - 1s 118us/step\n",
      "0.9829999995231629\n",
      "10000/10000 [==============================] - 1s 122us/step\n",
      "0.09816666662693024\n",
      "10000/10000 [==============================] - 1s 121us/step\n",
      "0.13299999996026357\n",
      "10000/10000 [==============================] - 1s 122us/step\n",
      "0.9806666661898296\n",
      "10000/10000 [==============================] - 1s 123us/step\n",
      "0.9821666661898295\n",
      "10000/10000 [==============================] - 1s 125us/step\n",
      "0.09799999996026357\n",
      "10000/10000 [==============================] - 1s 135us/step\n",
      "0.9804999995231628\n",
      "10000/10000 [==============================] - 1s 127us/step\n",
      "0.9821666661898295\n",
      "10000/10000 [==============================] - 1s 129us/step\n",
      "0.9853333328564962\n",
      "10000/10000 [==============================] - 1s 130us/step\n",
      "0.9859999995231629\n",
      "10000/10000 [==============================] - 1s 130us/step\n",
      "0.9819999995231629\n",
      "10000/10000 [==============================] - 1s 134us/step\n",
      "0.9828333334922791\n",
      "10000/10000 [==============================] - 1s 130us/step\n",
      "0.9831666661898295\n",
      "10000/10000 [==============================] - 1s 130us/step\n",
      "0.9818333328564962\n",
      "10000/10000 [==============================] - 1s 131us/step\n",
      "0.09799999996026357\n",
      "10000/10000 [==============================] - 1s 135us/step\n",
      "0.1348333332935969\n",
      "10000/10000 [==============================] - 1s 129us/step\n",
      "0.9828333328564962\n",
      "10000/10000 [==============================] - 1s 128us/step\n",
      "0.0978333332935969\n",
      "10000/10000 [==============================] - 1s 128us/step\n",
      "0.9838333328564962\n",
      "10000/10000 [==============================] - 1s 130us/step\n",
      "0.9764999995231628\n",
      "10000/10000 [==============================] - 1s 137us/step\n",
      "0.14083333327372868\n",
      "10000/10000 [==============================] - 1s 133us/step\n",
      "0.9854999995231628\n",
      "10000/10000 [==============================] - 1s 138us/step\n",
      "0.9823333328564962\n",
      "10000/10000 [==============================] - 1s 139us/step\n",
      "0.9848333328564962\n",
      "10000/10000 [==============================] - 1s 145us/step\n",
      "0.9801666661898295\n",
      "10000/10000 [==============================] - 1s 140us/step\n",
      "0.9838333328564962\n"
     ]
    }
   ],
   "source": [
    "def create_model(trainee, train_labels, testee, test_labels):\n",
    "\n",
    "\n",
    "    w_size = 3 #w_size= 3 is always recommended\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Conv2D(32,(w_size,w_size), activation='relu', input_shape=(36,36,2),\n",
    "                     data_format='channels_last', padding='same'))\n",
    "    model.add(Conv2D(32,(w_size,w_size), activation='relu', padding='same'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(64,(w_size,w_size), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64,(w_size,w_size), activation='relu', padding='same'))\n",
    "    model.add(Dropout({{uniform(0.1, 0.9)}}))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(128,(w_size,w_size), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128,(w_size,w_size), activation='relu', padding='same'))\n",
    "    model.add(Dropout({{uniform(0.1, 0.9)}}))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    if {{choice([0,1])}}: #Do we need to go deeper?\n",
    "        model.add(Conv2D(256,(w_size,w_size), activation='relu', padding='same'))\n",
    "        model.add(Conv2D(256,(w_size,w_size), activation='relu', padding='same'))\n",
    "        model.add(Dropout({{uniform(0.1, 0.9)}}))\n",
    "        model.add(MaxPool2D(pool_size=(2,2)))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(600, activation='relu'))\n",
    "    model.add(Dropout({{uniform(0.1, 0.9)}}))\n",
    "    model.add(Dense(10, activation='sigmoid')) \n",
    "\n",
    "    #parallel_model = ModelMGPU(model, gpus=num_GPU)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    history=model.fit(trainee, train_labels, batch_size=256, verbose=0, epochs=10, \n",
    "                  validation_split = 0.1)#, callbacks=[checkpoints])\n",
    "    \n",
    "    score=model.evaluate(testee, test_labels)\n",
    "    \n",
    "    #get the highest validation accuracy of the training epochs\n",
    "    validation_acc = np.amax(history.history['val_acc'])\n",
    "    print(validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                          data=data,\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trials=Trials(),\n",
    "                          notebook_name='v4_hyperas_optimized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "(60000, 36, 36, 1)\n",
      "(10000, 36, 36, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8196e8e0a7fc4f6db0b2bcf352ec07bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(60000, 36, 36, 2)\n",
      "(60000, 36, 36, 2)\n"
     ]
    }
   ],
   "source": [
    "trainee, train_labels, testee, test_labels=data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 143us/step\n",
      "[0.06189662295244634, 0.9852]\n"
     ]
    }
   ],
   "source": [
    "#from keras.models import Model, load_model\n",
    "#model=load_model('ft_models/weights.06.hdf5') #Numbering starts from 0\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score=best_model.evaluate(testee, test_labels, verbose=1)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dropout': 0.29543413894173454, 'Dropout_1': 0.6608108269941095, 'Dropout_2': 0, 'Dropout_3': 0.27616423774982984, 'Dropout_4': 0.254773388216778}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_401 (Conv2D)          (None, 36, 36, 32)        608       \n",
      "_________________________________________________________________\n",
      "conv2d_402 (Conv2D)          (None, 36, 36, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_201 (MaxPoolin (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_403 (Conv2D)          (None, 18, 18, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_404 (Conv2D)          (None, 18, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_201 (Dropout)        (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_202 (MaxPoolin (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_405 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_406 (Conv2D)          (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_202 (Dropout)        (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_203 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_61 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 600)               1229400   \n",
      "_________________________________________________________________\n",
      "dropout_203 (Dropout)        (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 10)                6010      \n",
      "=================================================================\n",
      "Total params: 1,522,130\n",
      "Trainable params: 1,522,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (best_run)\n",
    "print (best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dacc2118e6bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestee\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "preds=(model.predict(testee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=100\n",
    "f,axarr=plt.subplots(1,2,figsize=(8, 6))\n",
    "axarr[0].imshow(test_dataset[i].squeeze(),cmap='viridis')\n",
    "img=axarr[1].imshow(testee[i,:,:,1].squeeze(), cmap='viridis')\n",
    "plt.colorbar(img, fraction=0.046, pad=0.04)\n",
    "print (np.argmax(preds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "1_notmnist.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
